# **[Paper Reading]** Exploiting Generative Models in Discriminative Classifiers

Jaakkola et al.,

## Introduction
* Speech, vision and text are difficult to deal because of the size of sequences or arrays may have been distorted in particular ways. 
* It is common to estimate a generative model for such data, but using discriminative methods performs better.
* The problem is that there has been no systematic way to extract features or metric relations between examples for use with discriminative methods in the context of difficult data types.
* 
## Contribution
* Develop a combination of Generative and  discriminative model by deriving kernel functions for use in discriminative methods such as support vector machines from generative probability models.

## Method

### Kernel methods
![](https://i.imgur.com/YAe3Yim.png)
* X<sub>l</sub> : training set of examples 
* S<sub>l</sub> : binary labels  (±1)
*  the label for a new example X is obtained from a  weighted sum of the training labels.
*  The weighting of each training label S<sub>l</sub> consists of two parts:
    1. the overall importance of the example X<sub>l</sub> as summarized with a  coefficient λ<sub>l</sub> 
    2. a measure of pairwise "similarity" between between X<sub>l</sub> and X, expressed in terms of a  kernel function K(X<sub>l</sub>, X). 

#### Generalized linear models
* The probability of the label S given the example X and a parameter vector θ is given by:
![](https://i.imgur.com/pUHS9IU.png)
    * σ = logistic function
* Sssume the prior is a zero mean Gaussian with a possibly full covariance matrix Σ.
* Maximize a posteriori for the parameters 𝜃 given a training set of examples ![](https://i.imgur.com/zEw8THs.png)
    * solution form:
    ![](https://i.imgur.com/pXpdl2A.png)
* Inserting the above solution back into the conditional probability model gives:![](https://i.imgur.com/MFlTQpn.png)

### Kernels from generative probability models: the Fisher kernel
* Derived from generative probability models.
* Enhancing the discriminative power of the model and from an attempt to find a natural comparison between examples induced by the generative model.
* The Fisher score ![](https://i.imgur.com/HfKX5BH.png)
 maps an example X into a  feature vector 
     * note: ![](https://i.imgur.com/m68QeGp.png)
* call the mapping X -> Φ<sub>X</sub> the natural mapping of examples into feature vectors.
* Fisher kernel: ![](https://i.imgur.com/omR8PkO.png)
    * the information matrix is  immaterial, and the simpler kernel ![](https://i.imgur.com/icXxDR1.png)provides a suitable substitute for the Fisher kernel.

![](https://i.imgur.com/C8mhVRj.png)

## Experimental results

![](https://i.imgur.com/ALUJ5JW.png)
